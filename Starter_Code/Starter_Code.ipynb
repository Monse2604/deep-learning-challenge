{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import our dependencies\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EIN</th>\n",
       "      <th>NAME</th>\n",
       "      <th>APPLICATION_TYPE</th>\n",
       "      <th>AFFILIATION</th>\n",
       "      <th>CLASSIFICATION</th>\n",
       "      <th>USE_CASE</th>\n",
       "      <th>ORGANIZATION</th>\n",
       "      <th>STATUS</th>\n",
       "      <th>INCOME_AMT</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS</th>\n",
       "      <th>ASK_AMT</th>\n",
       "      <th>IS_SUCCESSFUL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10520599</td>\n",
       "      <td>BLUE KNIGHTS MOTORCYCLE CLUB</td>\n",
       "      <td>T10</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10531628</td>\n",
       "      <td>AMERICAN CHESAPEAKE CLUB CHARITABLE TR</td>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Co-operative</td>\n",
       "      <td>1</td>\n",
       "      <td>1-9999</td>\n",
       "      <td>N</td>\n",
       "      <td>108590</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10547893</td>\n",
       "      <td>ST CLOUD PROFESSIONAL FIREFIGHTERS</td>\n",
       "      <td>T5</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C3000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10553066</td>\n",
       "      <td>SOUTHSIDE ATHLETIC ASSOCIATION</td>\n",
       "      <td>T3</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>10000-24999</td>\n",
       "      <td>N</td>\n",
       "      <td>6692</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10556103</td>\n",
       "      <td>GENETIC RESEARCH INSTITUTE OF THE DESERT</td>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>Heathcare</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>100000-499999</td>\n",
       "      <td>N</td>\n",
       "      <td>142590</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        EIN                                      NAME APPLICATION_TYPE  \\\n",
       "0  10520599              BLUE KNIGHTS MOTORCYCLE CLUB              T10   \n",
       "1  10531628    AMERICAN CHESAPEAKE CLUB CHARITABLE TR               T3   \n",
       "2  10547893        ST CLOUD PROFESSIONAL FIREFIGHTERS               T5   \n",
       "3  10553066            SOUTHSIDE ATHLETIC ASSOCIATION               T3   \n",
       "4  10556103  GENETIC RESEARCH INSTITUTE OF THE DESERT               T3   \n",
       "\n",
       "        AFFILIATION CLASSIFICATION      USE_CASE  ORGANIZATION  STATUS  \\\n",
       "0       Independent          C1000    ProductDev   Association       1   \n",
       "1       Independent          C2000  Preservation  Co-operative       1   \n",
       "2  CompanySponsored          C3000    ProductDev   Association       1   \n",
       "3  CompanySponsored          C2000  Preservation         Trust       1   \n",
       "4       Independent          C1000     Heathcare         Trust       1   \n",
       "\n",
       "      INCOME_AMT SPECIAL_CONSIDERATIONS  ASK_AMT  IS_SUCCESSFUL  \n",
       "0              0                      N     5000              1  \n",
       "1         1-9999                      N   108590              1  \n",
       "2              0                      N     5000              0  \n",
       "3    10000-24999                      N     6692              1  \n",
       "4  100000-499999                      N   142590              1  "
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in the charity data\n",
    "application_df = pd.read_csv(\"https://static.bc-edx.com/data/dl-1-2/m21/lms/starter/charity_data.csv\")\n",
    "application_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the non-beneficial ID columns, 'EIN' and 'NAME'\n",
    "application_df = application_df.drop(columns=[\"EIN\", \"NAME\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "APPLICATION_TYPE            17\n",
       "AFFILIATION                  6\n",
       "CLASSIFICATION              71\n",
       "USE_CASE                     5\n",
       "ORGANIZATION                 4\n",
       "STATUS                       2\n",
       "INCOME_AMT                   9\n",
       "SPECIAL_CONSIDERATIONS       2\n",
       "ASK_AMT                   8747\n",
       "IS_SUCCESSFUL                2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the unique values in each column\n",
    "application_df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace rare categories with 'Other'\n",
    "for column in application_df.columns:\n",
    "    if application_df[column].nunique() > 10:  # Check for categorical columns with more than 10 unique values\n",
    "        value_counts = application_df[column].value_counts()\n",
    "        threshold = value_counts.values[10]  # Choose cutoff to combine rare categories\n",
    "        application_df[column] = application_df[column].apply(lambda x: x if value_counts[x] >= threshold else 'Other')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode categorical variables using pd.get_dummies\n",
    "application_df = pd.get_dummies(application_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the target and features\n",
    "y = application_df[\"IS_SUCCESSFUL\"]\n",
    "X = application_df.drop(\"IS_SUCCESSFUL\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing datasets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset indices to ensure proper alignment between features and targets\n",
    "X_train = X_train.reset_index(drop=True)\n",
    "X_test = X_test.reset_index(drop=True)\n",
    "y_train = y_train.reset_index(drop=True)\n",
    "y_test = y_test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the features using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the neural network model\n",
    "nn = tf.keras.Sequential([\n",
    "    # First hidden layer\n",
    "    tf.keras.layers.Dense(units=80, activation='relu', input_dim=X_train_scaled.shape[1]),\n",
    "    # Second hidden layer\n",
    "    tf.keras.layers.Dense(units=30, activation='relu'),\n",
    "    # Output layer\n",
    "    tf.keras.layers.Dense(units=1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_19 (Dense)            (None, 80)                16400     \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 30)                2430      \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 1)                 31        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 18,861\n",
      "Trainable params: 18,861\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Check the structure of the model\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "nn.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Keras is training/fitting/evaluating on array-like data. Keras may not be optimized for this format, so if your input data format is supported by TensorFlow I/O (https://github.com/tensorflow/io) we recommend using that to load a Dataset instead.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Keras is training/fitting/evaluating on array-like data. Keras may not be optimized for this format, so if your input data format is supported by TensorFlow I/O (https://github.com/tensorflow/io) we recommend using that to load a Dataset instead.\n",
      "429/429 [==============================] - 18s 40ms/step - loss: 0.5816 - accuracy: 0.7228 - val_loss: 0.5747 - val_accuracy: 0.7232\n",
      "Epoch 2/100\n",
      "429/429 [==============================] - 16s 37ms/step - loss: 0.5524 - accuracy: 0.7295 - val_loss: 0.5718 - val_accuracy: 0.7255\n",
      "Epoch 3/100\n",
      "429/429 [==============================] - 21s 49ms/step - loss: 0.5478 - accuracy: 0.7304 - val_loss: 0.5709 - val_accuracy: 0.7224\n",
      "Epoch 4/100\n",
      "429/429 [==============================] - 16s 37ms/step - loss: 0.5451 - accuracy: 0.7328 - val_loss: 0.5748 - val_accuracy: 0.7191\n",
      "Epoch 5/100\n",
      "429/429 [==============================] - 19s 44ms/step - loss: 0.5445 - accuracy: 0.7338 - val_loss: 0.5718 - val_accuracy: 0.7216\n",
      "Epoch 6/100\n",
      "429/429 [==============================] - 17s 40ms/step - loss: 0.5432 - accuracy: 0.7338 - val_loss: 0.5703 - val_accuracy: 0.7257\n",
      "Epoch 7/100\n",
      "429/429 [==============================] - 13s 31ms/step - loss: 0.5422 - accuracy: 0.7336 - val_loss: 0.5686 - val_accuracy: 0.7251\n",
      "Epoch 8/100\n",
      "429/429 [==============================] - 12s 28ms/step - loss: 0.5410 - accuracy: 0.7346 - val_loss: 0.5722 - val_accuracy: 0.7242\n",
      "Epoch 9/100\n",
      "429/429 [==============================] - 13s 30ms/step - loss: 0.5407 - accuracy: 0.7347 - val_loss: 0.5703 - val_accuracy: 0.7267\n",
      "Epoch 10/100\n",
      "429/429 [==============================] - 11s 27ms/step - loss: 0.5404 - accuracy: 0.7353 - val_loss: 0.5733 - val_accuracy: 0.7252\n",
      "Epoch 11/100\n",
      "429/429 [==============================] - 13s 30ms/step - loss: 0.5399 - accuracy: 0.7347 - val_loss: 0.5763 - val_accuracy: 0.7219\n",
      "Epoch 12/100\n",
      "429/429 [==============================] - 13s 30ms/step - loss: 0.5390 - accuracy: 0.7360 - val_loss: 0.5727 - val_accuracy: 0.7273\n",
      "Epoch 13/100\n",
      "429/429 [==============================] - 14s 32ms/step - loss: 0.5387 - accuracy: 0.7368 - val_loss: 0.5728 - val_accuracy: 0.7241\n",
      "Epoch 14/100\n",
      "429/429 [==============================] - 14s 33ms/step - loss: 0.5378 - accuracy: 0.7347 - val_loss: 0.5735 - val_accuracy: 0.7232\n",
      "Epoch 15/100\n",
      "429/429 [==============================] - 13s 30ms/step - loss: 0.5381 - accuracy: 0.7366 - val_loss: 0.5759 - val_accuracy: 0.7213\n",
      "Epoch 16/100\n",
      "429/429 [==============================] - 13s 30ms/step - loss: 0.5372 - accuracy: 0.7358 - val_loss: 0.5788 - val_accuracy: 0.7264\n",
      "Epoch 17/100\n",
      "429/429 [==============================] - 11s 26ms/step - loss: 0.5373 - accuracy: 0.7375 - val_loss: 0.5735 - val_accuracy: 0.7268\n",
      "Epoch 18/100\n",
      "429/429 [==============================] - 13s 30ms/step - loss: 0.5363 - accuracy: 0.7363 - val_loss: 0.5777 - val_accuracy: 0.7254\n",
      "Epoch 19/100\n",
      "429/429 [==============================] - 12s 28ms/step - loss: 0.5360 - accuracy: 0.7372 - val_loss: 0.5754 - val_accuracy: 0.7268\n",
      "Epoch 20/100\n",
      "429/429 [==============================] - 13s 30ms/step - loss: 0.5357 - accuracy: 0.7371 - val_loss: 0.5769 - val_accuracy: 0.7246\n",
      "Epoch 21/100\n",
      "429/429 [==============================] - 13s 30ms/step - loss: 0.5357 - accuracy: 0.7383 - val_loss: 0.5753 - val_accuracy: 0.7230\n",
      "Epoch 22/100\n",
      "429/429 [==============================] - 12s 29ms/step - loss: 0.5350 - accuracy: 0.7378 - val_loss: 0.5801 - val_accuracy: 0.7290\n",
      "Epoch 23/100\n",
      "429/429 [==============================] - 13s 30ms/step - loss: 0.5349 - accuracy: 0.7385 - val_loss: 0.5782 - val_accuracy: 0.7229\n",
      "Epoch 24/100\n",
      "429/429 [==============================] - 12s 28ms/step - loss: 0.5348 - accuracy: 0.7370 - val_loss: 0.5777 - val_accuracy: 0.7264\n",
      "Epoch 25/100\n",
      "429/429 [==============================] - 14s 32ms/step - loss: 0.5345 - accuracy: 0.7371 - val_loss: 0.5769 - val_accuracy: 0.7268\n",
      "Epoch 26/100\n",
      "429/429 [==============================] - 12s 28ms/step - loss: 0.5341 - accuracy: 0.7386 - val_loss: 0.5770 - val_accuracy: 0.7252\n",
      "Epoch 27/100\n",
      "429/429 [==============================] - 13s 30ms/step - loss: 0.5336 - accuracy: 0.7392 - val_loss: 0.5801 - val_accuracy: 0.7264\n",
      "Epoch 28/100\n",
      "429/429 [==============================] - 13s 30ms/step - loss: 0.5333 - accuracy: 0.7382 - val_loss: 0.5806 - val_accuracy: 0.7229\n",
      "Epoch 29/100\n",
      "429/429 [==============================] - 12s 28ms/step - loss: 0.5331 - accuracy: 0.7384 - val_loss: 0.5805 - val_accuracy: 0.7257\n",
      "Epoch 30/100\n",
      "429/429 [==============================] - 13s 31ms/step - loss: 0.5332 - accuracy: 0.7382 - val_loss: 0.5808 - val_accuracy: 0.7254\n",
      "Epoch 31/100\n",
      "429/429 [==============================] - 13s 29ms/step - loss: 0.5331 - accuracy: 0.7390 - val_loss: 0.5782 - val_accuracy: 0.7258\n",
      "Epoch 32/100\n",
      "429/429 [==============================] - 13s 30ms/step - loss: 0.5327 - accuracy: 0.7392 - val_loss: 0.5791 - val_accuracy: 0.7254\n",
      "Epoch 33/100\n",
      "429/429 [==============================] - 12s 29ms/step - loss: 0.5325 - accuracy: 0.7386 - val_loss: 0.5797 - val_accuracy: 0.7270\n",
      "Epoch 34/100\n",
      "429/429 [==============================] - 13s 30ms/step - loss: 0.5325 - accuracy: 0.7390 - val_loss: 0.5838 - val_accuracy: 0.7265\n",
      "Epoch 35/100\n",
      "429/429 [==============================] - 14s 32ms/step - loss: 0.5318 - accuracy: 0.7397 - val_loss: 0.5793 - val_accuracy: 0.7280\n",
      "Epoch 36/100\n",
      "429/429 [==============================] - 13s 30ms/step - loss: 0.5318 - accuracy: 0.7402 - val_loss: 0.5832 - val_accuracy: 0.7220\n",
      "Epoch 37/100\n",
      "429/429 [==============================] - 14s 33ms/step - loss: 0.5313 - accuracy: 0.7403 - val_loss: 0.5845 - val_accuracy: 0.7278\n",
      "Epoch 38/100\n",
      "429/429 [==============================] - 12s 28ms/step - loss: 0.5316 - accuracy: 0.7391 - val_loss: 0.5798 - val_accuracy: 0.7254\n",
      "Epoch 39/100\n",
      "429/429 [==============================] - 13s 32ms/step - loss: 0.5312 - accuracy: 0.7395 - val_loss: 0.5807 - val_accuracy: 0.7277\n",
      "Epoch 40/100\n",
      "429/429 [==============================] - 13s 31ms/step - loss: 0.5316 - accuracy: 0.7399 - val_loss: 0.5825 - val_accuracy: 0.7258\n",
      "Epoch 41/100\n",
      "429/429 [==============================] - 13s 31ms/step - loss: 0.5312 - accuracy: 0.7401 - val_loss: 0.5832 - val_accuracy: 0.7255\n",
      "Epoch 42/100\n",
      "429/429 [==============================] - 13s 30ms/step - loss: 0.5314 - accuracy: 0.7401 - val_loss: 0.5829 - val_accuracy: 0.7245\n",
      "Epoch 43/100\n",
      "429/429 [==============================] - 13s 30ms/step - loss: 0.5310 - accuracy: 0.7408 - val_loss: 0.5841 - val_accuracy: 0.7270\n",
      "Epoch 44/100\n",
      "429/429 [==============================] - 13s 30ms/step - loss: 0.5304 - accuracy: 0.7407 - val_loss: 0.5870 - val_accuracy: 0.7283\n",
      "Epoch 45/100\n",
      "429/429 [==============================] - 13s 30ms/step - loss: 0.5303 - accuracy: 0.7393 - val_loss: 0.5878 - val_accuracy: 0.7277\n",
      "Epoch 46/100\n",
      "429/429 [==============================] - 14s 32ms/step - loss: 0.5303 - accuracy: 0.7406 - val_loss: 0.5844 - val_accuracy: 0.7251\n",
      "Epoch 47/100\n",
      "429/429 [==============================] - 14s 32ms/step - loss: 0.5302 - accuracy: 0.7408 - val_loss: 0.5869 - val_accuracy: 0.7249\n",
      "Epoch 48/100\n",
      "429/429 [==============================] - 14s 33ms/step - loss: 0.5302 - accuracy: 0.7406 - val_loss: 0.5842 - val_accuracy: 0.7271\n",
      "Epoch 49/100\n",
      "429/429 [==============================] - 14s 32ms/step - loss: 0.5301 - accuracy: 0.7406 - val_loss: 0.5827 - val_accuracy: 0.7229\n",
      "Epoch 50/100\n",
      "429/429 [==============================] - 14s 33ms/step - loss: 0.5299 - accuracy: 0.7403 - val_loss: 0.5849 - val_accuracy: 0.7274\n",
      "Epoch 51/100\n",
      "429/429 [==============================] - 14s 32ms/step - loss: 0.5294 - accuracy: 0.7404 - val_loss: 0.5896 - val_accuracy: 0.7265\n",
      "Epoch 52/100\n",
      "429/429 [==============================] - 14s 34ms/step - loss: 0.5293 - accuracy: 0.7414 - val_loss: 0.5894 - val_accuracy: 0.7258\n",
      "Epoch 53/100\n",
      "429/429 [==============================] - 14s 33ms/step - loss: 0.5295 - accuracy: 0.7399 - val_loss: 0.5901 - val_accuracy: 0.7290\n",
      "Epoch 54/100\n",
      "429/429 [==============================] - 13s 31ms/step - loss: 0.5300 - accuracy: 0.7403 - val_loss: 0.5900 - val_accuracy: 0.7265\n",
      "Epoch 55/100\n",
      "429/429 [==============================] - 14s 32ms/step - loss: 0.5294 - accuracy: 0.7417 - val_loss: 0.5886 - val_accuracy: 0.7273\n",
      "Epoch 56/100\n",
      "429/429 [==============================] - 13s 30ms/step - loss: 0.5296 - accuracy: 0.7409 - val_loss: 0.5912 - val_accuracy: 0.7241\n",
      "Epoch 57/100\n",
      "429/429 [==============================] - 13s 31ms/step - loss: 0.5291 - accuracy: 0.7425 - val_loss: 0.5917 - val_accuracy: 0.7268\n",
      "Epoch 58/100\n",
      "429/429 [==============================] - 14s 33ms/step - loss: 0.5289 - accuracy: 0.7406 - val_loss: 0.5956 - val_accuracy: 0.7251\n",
      "Epoch 59/100\n",
      "429/429 [==============================] - 12s 29ms/step - loss: 0.5290 - accuracy: 0.7419 - val_loss: 0.5892 - val_accuracy: 0.7248\n",
      "Epoch 60/100\n",
      "429/429 [==============================] - 12s 29ms/step - loss: 0.5291 - accuracy: 0.7414 - val_loss: 0.5943 - val_accuracy: 0.7233\n",
      "Epoch 61/100\n",
      "429/429 [==============================] - 11s 25ms/step - loss: 0.5290 - accuracy: 0.7412 - val_loss: 0.5939 - val_accuracy: 0.7261\n",
      "Epoch 62/100\n",
      "429/429 [==============================] - 9s 21ms/step - loss: 0.5283 - accuracy: 0.7414 - val_loss: 0.5911 - val_accuracy: 0.7255\n",
      "Epoch 63/100\n",
      "429/429 [==============================] - 9s 21ms/step - loss: 0.5282 - accuracy: 0.7418 - val_loss: 0.5901 - val_accuracy: 0.7259\n",
      "Epoch 64/100\n",
      "429/429 [==============================] - 9s 21ms/step - loss: 0.5278 - accuracy: 0.7424 - val_loss: 0.5912 - val_accuracy: 0.7286\n",
      "Epoch 65/100\n",
      "429/429 [==============================] - 9s 21ms/step - loss: 0.5279 - accuracy: 0.7414 - val_loss: 0.5942 - val_accuracy: 0.7257\n",
      "Epoch 66/100\n",
      "429/429 [==============================] - 9s 21ms/step - loss: 0.5284 - accuracy: 0.7412 - val_loss: 0.5937 - val_accuracy: 0.7273\n",
      "Epoch 67/100\n",
      "429/429 [==============================] - 9s 22ms/step - loss: 0.5281 - accuracy: 0.7410 - val_loss: 0.5932 - val_accuracy: 0.7233\n",
      "Epoch 68/100\n",
      "429/429 [==============================] - 9s 21ms/step - loss: 0.5279 - accuracy: 0.7417 - val_loss: 0.5959 - val_accuracy: 0.7262\n",
      "Epoch 69/100\n",
      "429/429 [==============================] - 9s 21ms/step - loss: 0.5277 - accuracy: 0.7417 - val_loss: 0.5971 - val_accuracy: 0.7271\n",
      "Epoch 70/100\n",
      "429/429 [==============================] - 9s 22ms/step - loss: 0.5274 - accuracy: 0.7424 - val_loss: 0.5900 - val_accuracy: 0.7242\n",
      "Epoch 71/100\n",
      "429/429 [==============================] - 9s 21ms/step - loss: 0.5273 - accuracy: 0.7418 - val_loss: 0.5936 - val_accuracy: 0.7257\n",
      "Epoch 72/100\n",
      "429/429 [==============================] - 9s 21ms/step - loss: 0.5275 - accuracy: 0.7425 - val_loss: 0.5969 - val_accuracy: 0.7245\n",
      "Epoch 73/100\n",
      "429/429 [==============================] - 9s 21ms/step - loss: 0.5272 - accuracy: 0.7419 - val_loss: 0.5969 - val_accuracy: 0.7265\n",
      "Epoch 74/100\n",
      "429/429 [==============================] - 17s 40ms/step - loss: 0.5274 - accuracy: 0.7416 - val_loss: 0.5955 - val_accuracy: 0.7241\n",
      "Epoch 75/100\n",
      "429/429 [==============================] - 16s 38ms/step - loss: 0.5268 - accuracy: 0.7425 - val_loss: 0.5994 - val_accuracy: 0.7257\n",
      "Epoch 76/100\n",
      "429/429 [==============================] - 19s 44ms/step - loss: 0.5275 - accuracy: 0.7419 - val_loss: 0.6001 - val_accuracy: 0.7259\n",
      "Epoch 77/100\n",
      "429/429 [==============================] - 15s 35ms/step - loss: 0.5268 - accuracy: 0.7423 - val_loss: 0.5978 - val_accuracy: 0.7232\n",
      "Epoch 78/100\n",
      "429/429 [==============================] - 15s 34ms/step - loss: 0.5268 - accuracy: 0.7412 - val_loss: 0.6032 - val_accuracy: 0.7258\n",
      "Epoch 79/100\n",
      "429/429 [==============================] - 16s 37ms/step - loss: 0.5268 - accuracy: 0.7419 - val_loss: 0.5985 - val_accuracy: 0.7276\n",
      "Epoch 80/100\n",
      "429/429 [==============================] - 14s 32ms/step - loss: 0.5265 - accuracy: 0.7423 - val_loss: 0.5969 - val_accuracy: 0.7248\n",
      "Epoch 81/100\n",
      "429/429 [==============================] - 13s 31ms/step - loss: 0.5266 - accuracy: 0.7420 - val_loss: 0.5993 - val_accuracy: 0.7268\n",
      "Epoch 82/100\n",
      "429/429 [==============================] - 14s 32ms/step - loss: 0.5268 - accuracy: 0.7426 - val_loss: 0.5996 - val_accuracy: 0.7262\n",
      "Epoch 83/100\n",
      "429/429 [==============================] - 15s 34ms/step - loss: 0.5263 - accuracy: 0.7423 - val_loss: 0.5984 - val_accuracy: 0.7268\n",
      "Epoch 84/100\n",
      "429/429 [==============================] - 14s 34ms/step - loss: 0.5268 - accuracy: 0.7416 - val_loss: 0.5965 - val_accuracy: 0.7270\n",
      "Epoch 85/100\n",
      "429/429 [==============================] - 13s 31ms/step - loss: 0.5265 - accuracy: 0.7412 - val_loss: 0.5966 - val_accuracy: 0.7264\n",
      "Epoch 86/100\n",
      "429/429 [==============================] - 13s 30ms/step - loss: 0.5260 - accuracy: 0.7429 - val_loss: 0.6013 - val_accuracy: 0.7232\n",
      "Epoch 87/100\n",
      "429/429 [==============================] - 13s 29ms/step - loss: 0.5262 - accuracy: 0.7418 - val_loss: 0.5967 - val_accuracy: 0.7252\n",
      "Epoch 88/100\n",
      "429/429 [==============================] - 13s 30ms/step - loss: 0.5264 - accuracy: 0.7418 - val_loss: 0.6029 - val_accuracy: 0.7252\n",
      "Epoch 89/100\n",
      "429/429 [==============================] - 13s 31ms/step - loss: 0.5267 - accuracy: 0.7423 - val_loss: 0.5937 - val_accuracy: 0.7255\n",
      "Epoch 90/100\n",
      "429/429 [==============================] - 13s 30ms/step - loss: 0.5259 - accuracy: 0.7428 - val_loss: 0.5960 - val_accuracy: 0.7267\n",
      "Epoch 91/100\n",
      "429/429 [==============================] - 13s 30ms/step - loss: 0.5259 - accuracy: 0.7419 - val_loss: 0.6069 - val_accuracy: 0.7265\n",
      "Epoch 92/100\n",
      "429/429 [==============================] - 14s 33ms/step - loss: 0.5261 - accuracy: 0.7426 - val_loss: 0.5985 - val_accuracy: 0.7223\n",
      "Epoch 93/100\n",
      "429/429 [==============================] - 14s 32ms/step - loss: 0.5263 - accuracy: 0.7427 - val_loss: 0.6017 - val_accuracy: 0.7267\n",
      "Epoch 94/100\n",
      "429/429 [==============================] - 14s 34ms/step - loss: 0.5254 - accuracy: 0.7423 - val_loss: 0.6056 - val_accuracy: 0.7271\n",
      "Epoch 95/100\n",
      "429/429 [==============================] - 14s 32ms/step - loss: 0.5259 - accuracy: 0.7426 - val_loss: 0.5976 - val_accuracy: 0.7245\n",
      "Epoch 96/100\n",
      "429/429 [==============================] - 12s 29ms/step - loss: 0.5256 - accuracy: 0.7423 - val_loss: 0.5977 - val_accuracy: 0.7268\n",
      "Epoch 97/100\n",
      "429/429 [==============================] - 13s 29ms/step - loss: 0.5255 - accuracy: 0.7431 - val_loss: 0.6019 - val_accuracy: 0.7236\n",
      "Epoch 98/100\n",
      "429/429 [==============================] - 13s 30ms/step - loss: 0.5256 - accuracy: 0.7422 - val_loss: 0.6018 - val_accuracy: 0.7261\n",
      "Epoch 99/100\n",
      "429/429 [==============================] - 12s 29ms/step - loss: 0.5254 - accuracy: 0.7425 - val_loss: 0.6001 - val_accuracy: 0.7241\n",
      "Epoch 100/100\n",
      "429/429 [==============================] - 12s 28ms/step - loss: 0.5252 - accuracy: 0.7441 - val_loss: 0.6025 - val_accuracy: 0.7246\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = nn.fit(X_train_scaled, y_train, epochs=100, batch_size=64, validation_data=(X_test_scaled, y_test), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Keras is training/fitting/evaluating on array-like data. Keras may not be optimized for this format, so if your input data format is supported by TensorFlow I/O (https://github.com/tensorflow/io) we recommend using that to load a Dataset instead.\n",
      "215/215 - 1s - loss: 0.6025 - accuracy: 0.7246 - 990ms/epoch - 5ms/step\n",
      "Loss: 0.6025314927101135, Accuracy: 0.7246355414390564\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn.evaluate(X_test_scaled, y_test, verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the model to an HDF5 file\n",
    "nn.save('AlphabetSoupCharity.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
